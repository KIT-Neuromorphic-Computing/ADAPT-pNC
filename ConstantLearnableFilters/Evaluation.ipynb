{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c3cb27",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89333041-d172-4d95-b9b3-f2867ae037a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from utils import *\n",
    "from configuration import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists('./evaluation_date/'):\n",
    "    os.makedirs('./evaluation_date/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f071f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.DEVICE = 'cpu'\n",
    "args.task = 'temporal'\n",
    "args.metric = 'temporal_acc'\n",
    "args.SoftEva = True\n",
    "args = FormulateArgs(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb529a4e",
   "metadata": {},
   "source": [
    "## Results on non-augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa97109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.augment = False\n",
    "args.augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ace529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 4.6624109745025635 seconds\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.540848731994629 seconds\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.123783588409424 seconds\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.000450849533081 seconds\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "torch.Size([91, 1, 64])\n",
      "Inference Time for Batch 1: 2.126366138458252 seconds\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "torch.Size([91, 1, 64])\n",
      "Inference Time for Batch 1: 1.95809006690979 seconds\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "torch.Size([91, 1, 64])\n",
      "Inference Time for Batch 1: 2.150743007659912 seconds\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.3746578693389893 seconds\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 3.457167863845825 seconds\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 216, 'N_valid': 72, 'N_test': 72}\n",
      "torch.Size([72, 1, 64])\n",
      "Inference Time for Batch 1: 1.9872922897338867 seconds\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 1.9645800590515137 seconds\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 228, 'N_valid': 76, 'N_test': 76}\n",
      "torch.Size([76, 7, 64])\n",
      "Inference Time for Batch 1: 1.935521125793457 seconds\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.1239066123962402 seconds\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 180, 'N_valid': 60, 'N_test': 60}\n",
      "torch.Size([60, 1, 64])\n",
      "Inference Time for Batch 1: 2.342446804046631 seconds\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 4.304861307144165 seconds\n"
     ]
    }
   ],
   "source": [
    "results = torch.zeros([15])\n",
    "\n",
    "for ds in range(15):\n",
    "        args.DATASET = ds\n",
    "        seed = args.SEED\n",
    "        test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "        print(datainfo)\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        # aug_model_exist = os.path.isfile(f'../AugLearnableFilters/models/{modelname}')\n",
    "        # baseline_model_exist = os.path.isfile(f'../LastBaseline/LearnableFilters/models/{modelname}')\n",
    "        \n",
    "        # print(model_exist and aug_model_exist and baseline_model_exist)\n",
    "        # print(model_exist and aug_model_exist)\n",
    "        \n",
    "        \n",
    "        # if model_exist and aug_model_exist:\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            # aug_model = torch.load(f'../AugLearnableFilters/models/{modelname}', map_location=args.DEVICE)\n",
    "            # baseline_model = torch.load(f'../LastBaseline/LearnableFilters/models/{modelname}', map_location=baseline_args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            # aug_model.UpdateArgs(args)\n",
    "            # baseline_model.UpdateArgs(baseline_args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "                start_time = time.time()\n",
    "                model(X_test[:1, :, :])\n",
    "                end_time = time.time()\n",
    "                inference_time = end_time - start_time\n",
    "                results[ds] = inference_time\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            results[ds] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5beec48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"./evaluation1/inf_time_2Order_LPF_acc.txt\", results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55baa31",
   "metadata": {},
   "source": [
    "## Count devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82e085a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 216, 'N_valid': 72, 'N_test': 72}\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 228, 'N_valid': 76, 'N_test': 76}\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 180, 'N_valid': 60, 'N_test': 60}\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n"
     ]
    }
   ],
   "source": [
    "results = torch.zeros([15, 3])\n",
    "\n",
    "for ds in range(15):\n",
    "        args.DATASET = ds\n",
    "        seed = args.SEED\n",
    "        test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "        print(datainfo)\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        # aug_model_exist = os.path.isfile(f'../AugLearnableFilters/models/{modelname}')\n",
    "        # baseline_model_exist = os.path.isfile(f'../LastBaseline/LearnableFilters/models/{modelname}')\n",
    "        \n",
    "        # print(model_exist and aug_model_exist and baseline_model_exist)\n",
    "        # print(model_exist and aug_model_exist)\n",
    "        \n",
    "        \n",
    "        # if model_exist and aug_model_exist:\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            # aug_model = torch.load(f'../AugLearnableFilters/models/{modelname}', map_location=args.DEVICE)\n",
    "            # baseline_model = torch.load(f'../LastBaseline/LearnableFilters/models/{modelname}', map_location=baseline_args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            # aug_model.UpdateArgs(args)\n",
    "            # baseline_model.UpdateArgs(baseline_args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            state_dict = model.state_dict()\n",
    "            num_theta = 0\n",
    "            num_r = 0\n",
    "            num_c = 0\n",
    "            for name in state_dict:\n",
    "                if \"theta_\" in name:\n",
    "                    num_theta += state_dict[name].shape[0] * state_dict[name].shape[1]\n",
    "                elif \"R_\" in name:\n",
    "                    num_r +=1\n",
    "                elif \"C_\" in name:\n",
    "                    num_c += 1\n",
    "            \n",
    "            results[ds][0] = num_theta\n",
    "            results[ds][1] = num_r\n",
    "            results[ds][2] = num_c\n",
    "\n",
    "        else:\n",
    "            results[ds] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eefea9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"./evaluation1/count_device_2Order_LPF_acc.txt\", results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0281ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 216, 'N_valid': 72, 'N_test': 72}\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 228, 'N_valid': 76, 'N_test': 76}\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 180, 'N_valid': 60, 'N_test': 60}\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n"
     ]
    }
   ],
   "source": [
    "results = torch.zeros([15,10,6])\n",
    "\n",
    "for ds in range(15):\n",
    "    args.DATASET = ds\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "    test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "    print(datainfo)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        # aug_model_exist = os.path.isfile(f'../AugLearnableFilters/models/{modelname}')\n",
    "        # baseline_model_exist = os.path.isfile(f'../LastBaseline/LearnableFilters/models/{modelname}')\n",
    "        \n",
    "        # print(model_exist and aug_model_exist and baseline_model_exist)\n",
    "        # print(model_exist and aug_model_exist)\n",
    "        \n",
    "        \n",
    "        # if model_exist and aug_model_exist:\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            # aug_model = torch.load(f'../AugLearnableFilters/models/{modelname}', map_location=args.DEVICE)\n",
    "            # baseline_model = torch.load(f'../LastBaseline/LearnableFilters/models/{modelname}', map_location=baseline_args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            # aug_model.UpdateArgs(args)\n",
    "            # baseline_model.UpdateArgs(baseline_args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            for x,y in valid_loader:\n",
    "                X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "            acc_valid = evaluator(model, X_valid, y_valid)\n",
    "            acc_test   = evaluator(model, X_test,  y_test)\n",
    "            \n",
    "            # aug_acc_valid = evaluator(aug_model, X_valid, y_valid)\n",
    "            # aug_acc_test   = evaluator(aug_model, X_test,  y_test)\n",
    "            \n",
    "            # baseline_acc_valid = baseline_evaluator(baseline_model, X_valid, y_valid)\n",
    "            # baseline_acc_test   = baseline_evaluator(baseline_model, X_test,  y_test)\n",
    "\n",
    "            results[ds,seed,0] = acc_valid\n",
    "            results[ds,seed,1] = acc_test\n",
    "            \n",
    "            # results[ds,seed,2] = aug_acc_valid\n",
    "            # results[ds,seed,3] = aug_acc_test\n",
    "            \n",
    "            # results[ds,seed,4] = baseline_acc_valid\n",
    "            # results[ds,seed,5] = baseline_acc_test\n",
    "        else:\n",
    "            results[ds,seed,:] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fb7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,1], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/non_var_test_top_{N_selected_seeds}_2Order_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "556d6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,3], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/non_var_test_top_{N_selected_seeds}_aug_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef12b8",
   "metadata": {},
   "source": [
    "## Results on augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e19907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.augment = True\n",
    "args.augment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5bc8e",
   "metadata": {},
   "source": [
    "## Proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d483bb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './utils/act_model_package'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model_exist \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_exist)\n\u001b[0;32m---> 13\u001b[0m pnn \u001b[38;5;241m=\u001b[39m \u001b[43mpNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrintedNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatainfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mN_feature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatainfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mN_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_Channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_exist:  \n\u001b[1;32m     16\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mDEVICE)\n",
      "File \u001b[0;32m/hkfs/home/haicore/itec/qc0876/projects/Learnable-Filter/24_Second_Order_Variation_Learnable_Filter/PowerPrintedLearnableFilter.py:441\u001b[0m, in \u001b[0;36mPrintedNeuralNetwork.__init__\u001b[0;34m(self, args, N_channel, N_class, N_layer, N_feature, random_state)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mN_train\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39me_train\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mACT \u001b[38;5;241m=\u001b[39m \u001b[43mTanhRT\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mINV \u001b[38;5;241m=\u001b[39m InvRT(args)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# create pNN with learnable filters and weighted-sum\u001b[39;00m\n",
      "File \u001b[0;32m/hkfs/home/haicore/itec/qc0876/projects/Learnable-Filter/24_Second_Order_Variation_Learnable_Filter/pLNC.py:106\u001b[0m, in \u001b[0;36mTanhRT.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrt_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(\n\u001b[1;32m    103\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor([args\u001b[38;5;241m.\u001b[39mACT_R1n, args\u001b[38;5;241m.\u001b[39mACT_R2n, args\u001b[38;5;241m.\u001b[39mACT_W1n, args\u001b[38;5;241m.\u001b[39mACT_L1n, args\u001b[38;5;241m.\u001b[39mACT_W2n, args\u001b[38;5;241m.\u001b[39mACT_L2n]), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m package \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./utils/act_model_package\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_estimator \u001b[38;5;241m=\u001b[39m package[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta_estimator\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_estimator\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/train-model/lib/python3.12/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/train-model/lib/python3.12/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/train-model/lib/python3.12/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './utils/act_model_package'"
     ]
    }
   ],
   "source": [
    "import PowerPrintedLearnableFilter as pNN\n",
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "for ds in range(15):\n",
    "    args.DATASET = ds\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "        valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        print(model_exist)\n",
    "        pnn = pNN.PrintedNeuralNetwork(args, datainfo['N_feature'], datainfo['N_class'], args.N_Channel, N_feature=args.N_feature).to(args.DEVICE)\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            pnn.load_state_dict(model.state_dict())\n",
    "            pnn.UpdateArgs(args)\n",
    "            \n",
    "            print(pnn.MAC_power)\n",
    "\n",
    "            # SetSeed(args.SEED)\n",
    "\n",
    "#             evaluator = Evaluator(args).to(args.DEVICE)\n",
    "#             # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "#             for x,y in valid_loader:\n",
    "#                 X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "#             for x,y in test_loader:\n",
    "#                 X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "#             acc_valid = evaluator(model, X_valid, y_valid)\n",
    "#             acc_test   = evaluator(model, X_test,  y_test)\n",
    "\n",
    "#             results[ds,seed,0] = acc_valid\n",
    "#             results[ds,seed,1] = acc_test\n",
    "            \n",
    "#             inference_time = 0\n",
    "            \n",
    "#             for x,y in test_loader:\n",
    "#                 X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "#                 start_time = time.time()\n",
    "#                 model(X_test[:1, :, :])\n",
    "#                 end_time = time.time()\n",
    "#                 inference_time = end_time - start_time\n",
    "#                 break\n",
    "#             results[ds, seed, 2] = inference_time\n",
    "            \n",
    "#             # results[ds,seed,3] = area_test\n",
    "#             # results[ds,seed,4] = power_test\n",
    "            \n",
    "#         else:\n",
    "#             results[ds,seed,:] = float('nan')\n",
    "            \n",
    "#         temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "#         all_results.append(temp_result)\n",
    "\n",
    "# columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "# all_results.sort(key=lambda x: x[0])            \n",
    "# df = pd.DataFrame(all_results, columns=columns)\n",
    "# # Save the DataFrame to an Excel file\n",
    "# if not os.path.exists(f\"./evaluation2_date/\"):\n",
    "#     os.makedirs(f\"./evaluation2_date/\")\n",
    "# excel_filename = f\"./evaluation2_date/augment_{args.augment}_proposed_evaluation_results_analysis.xlsx\"\n",
    "# df.to_excel(excel_filename, index=False)\n",
    "# print(f\"Results have been saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe1ae00-dcac-4410-bfbb-25287ab417ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 540, 'N_valid': 180, 'N_test': 182}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 540, 'N_valid': 180, 'N_test': 182}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 540, 'N_valid': 180, 'N_test': 182}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 432, 'N_valid': 144, 'N_test': 144}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 456, 'N_valid': 152, 'N_test': 152}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 360, 'N_valid': 120, 'N_test': 120}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Results have been saved to ./evaluation2_date/augment_True_proposed_evaluation_results_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "for ds in range(15):\n",
    "    args.DATASET = ds\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "    test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')  \n",
    "    print(datainfo)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "\n",
    "        print(model_exist)\n",
    "        \n",
    "        \n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            model.UpdateArgs(args)\n",
    "\n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            for x,y in valid_loader:\n",
    "                X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "            acc_valid = evaluator(model, X_valid, y_valid)\n",
    "            acc_test   = evaluator(model, X_test,  y_test)\n",
    "\n",
    "            results[ds,seed,0] = acc_valid\n",
    "            results[ds,seed,1] = acc_test\n",
    "            \n",
    "            inference_time = 0\n",
    "            \n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "                start_time = time.time()\n",
    "                model(X_test[:1, :, :])\n",
    "                end_time = time.time()\n",
    "                inference_time = end_time - start_time\n",
    "                break\n",
    "            results[ds, seed, 2] = inference_time\n",
    "            \n",
    "            # results[ds,seed,3] = area_test\n",
    "            # results[ds,seed,4] = power_test\n",
    "            \n",
    "        else:\n",
    "            results[ds,seed,:] = float('nan')\n",
    "            \n",
    "        temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "        all_results.append(temp_result)\n",
    "\n",
    "columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "all_results.sort(key=lambda x: x[0])            \n",
    "df = pd.DataFrame(all_results, columns=columns)\n",
    "# Save the DataFrame to an Excel file\n",
    "if not os.path.exists(f\"./evaluation2_date/\"):\n",
    "    os.makedirs(f\"./evaluation2_date/\")\n",
    "excel_filename = f\"./evaluation2_date/augment_{args.augment}_proposed_evaluation_results_analysis.xlsx\"\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Results have been saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1ed4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,1], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/var_test_top_{N_selected_seeds}_var_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c967fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,3], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/var_test_top_{N_selected_seeds}_aug_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e92949",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "for ds in range(9):\n",
    "    args.DATASET = ds\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "    test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')  \n",
    "    print(datainfo)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        # aug_model_exist = os.path.isfile(f'../AugLearnableFilters/models/{modelname}')\n",
    "        # baseline_model_exist = os.path.isfile(f'../LastBaseline/LearnableFilters/models/{modelname}')\n",
    "        \n",
    "        # print(model_exist and aug_model_exist and baseline_model_exist)\n",
    "        print(model_exist)\n",
    "        \n",
    "        \n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            # aug_model = torch.load(f'../AugLearnableFilters/models/{modelname}', map_location=args.DEVICE)\n",
    "            # baseline_model = torch.load(f'../LastBaseline/LearnableFilters/models/{modelname}', map_location=baseline_args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            # aug_model.UpdateArgs(args)\n",
    "            # baseline_model.UpdateArgs(baseline_args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            for x,y in valid_loader:\n",
    "                X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "            acc_valid = evaluator(model, X_valid, y_valid)\n",
    "            acc_test   = evaluator(model, X_test,  y_test)\n",
    "            \n",
    "            # aug_acc_valid = evaluator(aug_model, X_valid, y_valid)\n",
    "            # aug_acc_test   = evaluator(aug_model, X_test,  y_test)\n",
    "            \n",
    "            # baseline_acc_valid = baseline_evaluator(baseline_model, X_valid, y_valid)\n",
    "            # baseline_acc_test   = baseline_evaluator(baseline_model, X_test,  y_test)\n",
    "\n",
    "            results[ds,seed,0] = acc_valid\n",
    "            results[ds,seed,1] = acc_test\n",
    "            \n",
    "            # results[ds,seed,2] = aug_acc_valid\n",
    "            # results[ds,seed,3] = aug_acc_test\n",
    "            \n",
    "            # results[ds,seed,4] = baseline_acc_valid\n",
    "            # results[ds,seed,5] = baseline_acc_test\n",
    "        else:\n",
    "            results[ds,seed,:] = float('nan')\n",
    "            \n",
    "        inference_time = 0\n",
    "            \n",
    "        for x,y in test_loader:\n",
    "            X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            start_time = time.time()\n",
    "            model(X_test[:1, :, :])\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            break\n",
    "        results[ds, seed, 2] = inference_time\n",
    "            \n",
    "        temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "        all_results.append(temp_result)\n",
    "\n",
    "columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "all_results.sort(key=lambda x: x[0])            \n",
    "df = pd.DataFrame(all_results, columns=columns)\n",
    "# Save the DataFrame to an Excel file\n",
    "if not os.path.exists(f\"./evaluation/\"):\n",
    "    os.makedirs(f\"./evaluation/\")\n",
    "excel_filename = f\"./evaluation/ELMAN_evaluation_results_analysis.xlsx\"\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Results have been saved to {excel_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
