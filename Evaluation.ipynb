{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c3cb27",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89333041-d172-4d95-b9b3-f2867ae037a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from utils import *\n",
    "from configuration import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists('./evaluation_date/'):\n",
    "    os.makedirs('./evaluation_date/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f071f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.DEVICE = 'cpu'\n",
    "args.task = 'temporal'\n",
    "args.metric = 'temporal_acc'\n",
    "args.SoftEva = True\n",
    "args = FormulateArgs(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb529a4e",
   "metadata": {},
   "source": [
    "## Results on non-augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa97109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.augment = False\n",
    "args.augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ace529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 4.6624109745025635 seconds\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.540848731994629 seconds\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.123783588409424 seconds\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.000450849533081 seconds\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "torch.Size([91, 1, 64])\n",
      "Inference Time for Batch 1: 2.126366138458252 seconds\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "torch.Size([91, 1, 64])\n",
      "Inference Time for Batch 1: 1.95809006690979 seconds\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "torch.Size([91, 1, 64])\n",
      "Inference Time for Batch 1: 2.150743007659912 seconds\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.3746578693389893 seconds\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 3.457167863845825 seconds\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 216, 'N_valid': 72, 'N_test': 72}\n",
      "torch.Size([72, 1, 64])\n",
      "Inference Time for Batch 1: 1.9872922897338867 seconds\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 1.9645800590515137 seconds\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 228, 'N_valid': 76, 'N_test': 76}\n",
      "torch.Size([76, 7, 64])\n",
      "Inference Time for Batch 1: 1.935521125793457 seconds\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 2.1239066123962402 seconds\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 180, 'N_valid': 60, 'N_test': 60}\n",
      "torch.Size([60, 1, 64])\n",
      "Inference Time for Batch 1: 2.342446804046631 seconds\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "torch.Size([100, 1, 64])\n",
      "Inference Time for Batch 1: 4.304861307144165 seconds\n"
     ]
    }
   ],
   "source": [
    "results = torch.zeros([15])\n",
    "\n",
    "for ds in range(15):\n",
    "        args.DATASET = ds\n",
    "        seed = args.SEED\n",
    "        test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "        print(datainfo)\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "                start_time = time.time()\n",
    "                model(X_test[:1, :, :])\n",
    "                end_time = time.time()\n",
    "                inference_time = end_time - start_time\n",
    "                results[ds] = inference_time\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            results[ds] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5beec48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"./evaluation1/inf_time_2Order_LPF_acc.txt\", results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55baa31",
   "metadata": {},
   "source": [
    "## Count devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82e085a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 216, 'N_valid': 72, 'N_test': 72}\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 228, 'N_valid': 76, 'N_test': 76}\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 180, 'N_valid': 60, 'N_test': 60}\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n"
     ]
    }
   ],
   "source": [
    "results = torch.zeros([15, 3])\n",
    "\n",
    "for ds in range(15):\n",
    "        args.DATASET = ds\n",
    "        seed = args.SEED\n",
    "        test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "        print(datainfo)\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "\n",
    "            state_dict = model.state_dict()\n",
    "            num_theta = 0\n",
    "            num_r = 0\n",
    "            num_c = 0\n",
    "            for name in state_dict:\n",
    "                if \"theta_\" in name:\n",
    "                    num_theta += state_dict[name].shape[0] * state_dict[name].shape[1]\n",
    "                elif \"R_\" in name:\n",
    "                    num_r +=1\n",
    "                elif \"C_\" in name:\n",
    "                    num_c += 1\n",
    "            \n",
    "            results[ds][0] = num_theta\n",
    "            results[ds][1] = num_r\n",
    "            results[ds][2] = num_c\n",
    "\n",
    "        else:\n",
    "            results[ds] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eefea9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"./evaluation1/count_device_2Order_LPF_acc.txt\", results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0281ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 216, 'N_valid': 72, 'N_test': 72}\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 228, 'N_valid': 76, 'N_test': 76}\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 180, 'N_valid': 60, 'N_test': 60}\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n"
     ]
    }
   ],
   "source": [
    "results = torch.zeros([15,10,6])\n",
    "\n",
    "for ds in range(15):\n",
    "    args.DATASET = ds\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "    test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "    print(datainfo)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        \n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "\n",
    "            for x,y in valid_loader:\n",
    "                X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "            acc_valid = evaluator(model, X_valid, y_valid)\n",
    "            acc_test   = evaluator(model, X_test,  y_test)\n",
    "\n",
    "            results[ds,seed,0] = acc_valid\n",
    "            results[ds,seed,1] = acc_test\n",
    "            \n",
    "        else:\n",
    "            results[ds,seed,:] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fb7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,1], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/non_var_test_top_{N_selected_seeds}_2Order_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "556d6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,3], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/non_var_test_top_{N_selected_seeds}_aug_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef12b8",
   "metadata": {},
   "source": [
    "## Results on augmented test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e166ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PrintedLearnableFilter as pNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e19907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.augment = True\n",
    "args.augment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5bc8e",
   "metadata": {},
   "source": [
    "## Proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d483bb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PrintedNeuralNetwork' object has no attribute 'MAC_power'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;66;03m# pnn.load_state_dict(model.state_dict())\u001b[39;00m\n\u001b[1;32m     18\u001b[0m             model\u001b[38;5;241m.\u001b[39mUpdateArgs(args)\n\u001b[0;32m---> 20\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[43mpnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAC_power\u001b[49m)\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;66;03m# SetSeed(args.SEED)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#             evaluator = Evaluator(args).to(args.DEVICE)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# df.to_excel(excel_filename, index=False)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# print(f\"Results have been saved to {excel_filename}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/train-model/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrintedNeuralNetwork' object has no attribute 'MAC_power'"
     ]
    }
   ],
   "source": [
    "\n",
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "for ds in range(15):\n",
    "    args.DATASET = ds\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "        valid_loader, datainfo = GetDataLoader(args, 'valid', path='./dataset/')\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        model_exist = os.path.isfile(f'./ConstantLearnableFilters/models/{modelname}')\n",
    "        print(model_exist)\n",
    "        pnn = pNN.PrintedNeuralNetwork(args, datainfo['N_feature'], datainfo['N_class'], args.N_Channel, N_feature=args.N_feature).to(args.DEVICE)\n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./ConstantLearnableFilters/models/{modelname}', map_location=args.DEVICE)\n",
    "            # pnn.load_state_dict(model.state_dict())\n",
    "            model.UpdateArgs(args)\n",
    "            \n",
    "            # print(pnn.MAC_power)\n",
    "\n",
    "            # SetSeed(args.SEED)\n",
    "\n",
    "#             evaluator = Evaluator(args).to(args.DEVICE)\n",
    "#             # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            # for x,y in valid_loader:\n",
    "            #     X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x, y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "#             acc_valid = evaluator(model, X_valid, y_valid)\n",
    "#             acc_test   = evaluator(model, X_test,  y_test)\n",
    "\n",
    "#             results[ds,seed,0] = acc_valid\n",
    "#             results[ds,seed,1] = acc_test\n",
    "            \n",
    "#             inference_time = 0\n",
    "            \n",
    "#             for x,y in test_loader:\n",
    "#                 X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "#                 start_time = time.time()\n",
    "#                 model(X_test[:1, :, :])\n",
    "#                 end_time = time.time()\n",
    "#                 inference_time = end_time - start_time\n",
    "#                 break\n",
    "#             results[ds, seed, 2] = inference_time\n",
    "            \n",
    "#             # results[ds,seed,3] = area_test\n",
    "#             # results[ds,seed,4] = power_test\n",
    "            \n",
    "#         else:\n",
    "#             results[ds,seed,:] = float('nan')\n",
    "            \n",
    "#         temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "#         all_results.append(temp_result)\n",
    "\n",
    "# columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "# all_results.sort(key=lambda x: x[0])            \n",
    "# df = pd.DataFrame(all_results, columns=columns)\n",
    "# # Save the DataFrame to an Excel file\n",
    "# if not os.path.exists(f\"./evaluation2_date/\"):\n",
    "#     os.makedirs(f\"./evaluation2_date/\")\n",
    "# excel_filename = f\"./evaluation2_date/augment_{args.augment}_proposed_evaluation_results_analysis.xlsx\"\n",
    "# df.to_excel(excel_filename, index=False)\n",
    "# print(f\"Results have been saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe1ae00-dcac-4410-bfbb-25287ab417ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 540, 'N_valid': 180, 'N_test': 182}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'gunpointmaleversusfemale', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 540, 'N_valid': 180, 'N_test': 182}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'gunpointoldversusyoung', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 540, 'N_valid': 180, 'N_test': 182}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'middlephalanxoutlineagegroup', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'mixedshapesregulartrain', 'N_feature': 1, 'N_class': 5, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'powercons', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 432, 'N_valid': 144, 'N_test': 144}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'proximalphalanxoutlinecorrect', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'selfregulationscp2', 'N_feature': 7, 'N_class': 2, 'N_time': 64, 'N_train': 456, 'N_valid': 152, 'N_test': 152}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'slope', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'smoothsubspace', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 360, 'N_valid': 120, 'N_test': 120}\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "{'dataname': 'symbols', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 600, 'N_valid': 200, 'N_test': 200}\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Results have been saved to ./evaluation2_date/augment_True_proposed_evaluation_results_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "for ds in range(15):\n",
    "    args.DATASET = ds\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "    test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')  \n",
    "    print(datainfo)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "\n",
    "        print(model_exist)\n",
    "        \n",
    "        \n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            model.UpdateArgs(args)\n",
    "\n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            for x,y in valid_loader:\n",
    "                X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "            acc_valid = evaluator(model, X_valid, y_valid)\n",
    "            acc_test   = evaluator(model, X_test,  y_test)\n",
    "\n",
    "            results[ds,seed,0] = acc_valid\n",
    "            results[ds,seed,1] = acc_test\n",
    "            \n",
    "            inference_time = 0\n",
    "            \n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "                start_time = time.time()\n",
    "                model(X_test[:1, :, :])\n",
    "                end_time = time.time()\n",
    "                inference_time = end_time - start_time\n",
    "                break\n",
    "            results[ds, seed, 2] = inference_time\n",
    "            \n",
    "            # results[ds,seed,3] = area_test\n",
    "            # results[ds,seed,4] = power_test\n",
    "            \n",
    "        else:\n",
    "            results[ds,seed,:] = float('nan')\n",
    "            \n",
    "        temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "        all_results.append(temp_result)\n",
    "\n",
    "columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "all_results.sort(key=lambda x: x[0])            \n",
    "df = pd.DataFrame(all_results, columns=columns)\n",
    "# Save the DataFrame to an Excel file\n",
    "if not os.path.exists(f\"./evaluation2_date/\"):\n",
    "    os.makedirs(f\"./evaluation2_date/\")\n",
    "excel_filename = f\"./evaluation2_date/augment_{args.augment}_proposed_evaluation_results_analysis.xlsx\"\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Results have been saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1ed4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,1], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/var_test_top_{N_selected_seeds}_var_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c967fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_selected_seeds = 3\n",
    "re_temp = torch.nan_to_num(results, nan=-10000.)\n",
    "values, indices = torch.topk(re_temp[:,:,3], k=N_selected_seeds, dim=1)\n",
    "mean_selected = torch.mean(torch.asarray(values), dim=1)\n",
    "var_selected = torch.std(torch.asarray(values), dim=1)\n",
    "selected_results = torch.cat([mean_selected.unsqueeze(-1), var_selected.unsqueeze(-1)], dim=1)\n",
    "\n",
    "np.savetxt(f\"./evaluation1/var_test_top_{N_selected_seeds}_aug_LPF_acc.txt\", selected_results.numpy(), delimiter=\"\\t\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e92949",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "for ds in range(9):\n",
    "    args.DATASET = ds\n",
    "    valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "    test_loader , datainfo = GetDataLoader(args, 'test',  path='../dataset/')  \n",
    "    print(datainfo)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "\n",
    "\n",
    "        modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "        \n",
    "        model_exist = os.path.isfile(f'./models/{modelname}')\n",
    "        # aug_model_exist = os.path.isfile(f'../AugLearnableFilters/models/{modelname}')\n",
    "        # baseline_model_exist = os.path.isfile(f'../LastBaseline/LearnableFilters/models/{modelname}')\n",
    "        \n",
    "        # print(model_exist and aug_model_exist and baseline_model_exist)\n",
    "        print(model_exist)\n",
    "        \n",
    "        \n",
    "        if model_exist:  \n",
    "                          \n",
    "            model = torch.load(f'./models/{modelname}', map_location=args.DEVICE)\n",
    "            # aug_model = torch.load(f'../AugLearnableFilters/models/{modelname}', map_location=args.DEVICE)\n",
    "            # baseline_model = torch.load(f'../LastBaseline/LearnableFilters/models/{modelname}', map_location=baseline_args.DEVICE)\n",
    "            \n",
    "            model.UpdateArgs(args)\n",
    "            # aug_model.UpdateArgs(args)\n",
    "            # baseline_model.UpdateArgs(baseline_args)\n",
    "            \n",
    "            SetSeed(args.SEED)\n",
    "\n",
    "            evaluator = Evaluator(args).to(args.DEVICE)\n",
    "            # baseline_evaluator = baselineEvaluator(baseline_args).to(baseline_args.DEVICE)\n",
    "\n",
    "            for x,y in valid_loader:\n",
    "                X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "            acc_valid = evaluator(model, X_valid, y_valid)\n",
    "            acc_test   = evaluator(model, X_test,  y_test)\n",
    "            \n",
    "            # aug_acc_valid = evaluator(aug_model, X_valid, y_valid)\n",
    "            # aug_acc_test   = evaluator(aug_model, X_test,  y_test)\n",
    "            \n",
    "            # baseline_acc_valid = baseline_evaluator(baseline_model, X_valid, y_valid)\n",
    "            # baseline_acc_test   = baseline_evaluator(baseline_model, X_test,  y_test)\n",
    "\n",
    "            results[ds,seed,0] = acc_valid\n",
    "            results[ds,seed,1] = acc_test\n",
    "            \n",
    "            # results[ds,seed,2] = aug_acc_valid\n",
    "            # results[ds,seed,3] = aug_acc_test\n",
    "            \n",
    "            # results[ds,seed,4] = baseline_acc_valid\n",
    "            # results[ds,seed,5] = baseline_acc_test\n",
    "        else:\n",
    "            results[ds,seed,:] = float('nan')\n",
    "            \n",
    "        inference_time = 0\n",
    "            \n",
    "        for x,y in test_loader:\n",
    "            X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "            start_time = time.time()\n",
    "            model(X_test[:1, :, :])\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            break\n",
    "        results[ds, seed, 2] = inference_time\n",
    "            \n",
    "        temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "        all_results.append(temp_result)\n",
    "\n",
    "columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "all_results.sort(key=lambda x: x[0])            \n",
    "df = pd.DataFrame(all_results, columns=columns)\n",
    "# Save the DataFrame to an Excel file\n",
    "if not os.path.exists(f\"./evaluation/\"):\n",
    "    os.makedirs(f\"./evaluation/\")\n",
    "excel_filename = f\"./evaluation/ELMAN_evaluation_results_analysis.xlsx\"\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Results have been saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bd796",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7644d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import pprint\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from utils import *\n",
    "from configuration import *\n",
    "import PrintedLearnableFilter as pNN\n",
    "\n",
    "if not os.path.exists('./evaluation/'):\n",
    "    os.makedirs('./evaluation/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd081313",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.DEVICE = 'cpu'\n",
    "args.task = 'temporal'\n",
    "args.metric = 'temporal_acc'\n",
    "args.SoftEva = True\n",
    "args.augment = True\n",
    "# args.DS_VAR = 'magnitude_scaling'\n",
    "# args.DS_VAR = 'time_warping'\n",
    "args.DS_VAR = 'jittering'\n",
    "args = FormulateArgs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff5e7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_datasets = ['Dataset_cbf.tsds',\n",
    "                         'Dataset_distalphalanxtw.tsds',\n",
    "                         'Dataset_freezerregulartrain.tsds',\n",
    "                         'Dataset_freezersmalltrain.tsds',\n",
    "                         'Dataset_gunpointagespan.tsds',\n",
    "                         'Dataset_gunpointmaleversusfemale.tsds',\n",
    "                         'Dataset_gunpointoldversusyoung.tsds',\n",
    "                         'Dataset_middlephalanxoutlineagegroup.tsds',\n",
    "                         'Dataset_mixedshapesregulartrain.tsds',\n",
    "                         'Dataset_powercons.tsds',\n",
    "                         'Dataset_proximalphalanxoutlinecorrect.tsds',\n",
    "                         'Dataset_selfregulationscp2.tsds',\n",
    "                         'Dataset_slope.tsds',\n",
    "                         'Dataset_smoothsubspace.tsds',\n",
    "                         'Dataset_symbols.tsds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce3522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = range(len(temporal_datasets))\n",
    "project_name = 'VariationAnalysis'\n",
    "# var_ratio = [0.0, 0.05, 0.1]\n",
    "var_ratio = [0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6fadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize variables for saving the data\n",
    "trained_model = None\n",
    "\n",
    "for var in var_ratio:\n",
    "    pn=str(int(var*100))+'_'+project_name\n",
    "    args.project_name = pn\n",
    "    # print(pn)\n",
    "    for seed in range(10):\n",
    "        args.SEED = seed\n",
    "        for ds in dataset:\n",
    "            args.DATASET = ds\n",
    "            valid_loader, datainfo = GetDataLoader(args, 'valid', path='./dataset/')\n",
    "            modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "            # print(modelname)\n",
    "            model_file = f\"./{pn}/models/{modelname}\"\n",
    "            # model_file = f\"./{pn}/models/{modelname}\"\n",
    "            # model_file = f\"./{pn}/models/{modelname}\"\n",
    "            if not os.path.exists(model_file):\n",
    "                print(f\"Model {model_file} does not exist\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43425232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataname': 'cbf', 'N_feature': 1, 'N_class': 3, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'distalphalanxtw', 'N_feature': 1, 'N_class': 6, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezerregulartrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'freezersmalltrain', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 300, 'N_valid': 100, 'N_test': 100}\n",
      "{'dataname': 'gunpointagespan', 'N_feature': 1, 'N_class': 2, 'N_time': 64, 'N_train': 270, 'N_valid': 90, 'N_test': 91}\n"
     ]
    }
   ],
   "source": [
    "args.augment = True\n",
    "all_results = []\n",
    "results = torch.zeros([15,10,6])\n",
    "\n",
    "for var in var_ratio:\n",
    "    pn=str(int(var*100))+'_'+project_name\n",
    "    args.project_name = pn\n",
    "    args.e_train = var\n",
    "    args.e_test = var\n",
    "    for ds in dataset:\n",
    "        args.DATASET = ds\n",
    "        valid_loader, datainfo = GetDataLoader(args, 'valid', path='./dataset/')\n",
    "        test_loader , datainfo = GetDataLoader(args, 'test',  path='./dataset/')  \n",
    "        print(datainfo)\n",
    "        for seed in range(10):\n",
    "            args.SEED = seed\n",
    "            \n",
    "            modelname = f\"pLF_data_{ds:02d}_{datainfo['dataname']}_seed_{seed:02d}.model\"\n",
    "            model_file = f\"./{pn}/models/{modelname}\"\n",
    "            model_exist = os.path.isfile(model_file)\n",
    "            \n",
    "            if not model_exist:\n",
    "                print(f\"Model {model_file} does not exist\")\n",
    "                continue\n",
    "            \n",
    "            if model_exist:  \n",
    "                            \n",
    "                model = torch.load(model_file, map_location=args.DEVICE)\n",
    "                model.UpdateArgs(args)\n",
    "                \n",
    "                # SetSeed(args.SEED)\n",
    "\n",
    "                evaluator = Evaluator(args).to(args.DEVICE)\n",
    "\n",
    "                for x,y in valid_loader:\n",
    "                    X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "                for x,y in test_loader:\n",
    "                    X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "\n",
    "                acc_valid = evaluator(model, X_valid, y_valid)\n",
    "                acc_test   = evaluator(model, X_test,  y_test)\n",
    "\n",
    "                results[ds,seed,0] = acc_valid\n",
    "                results[ds,seed,1] = acc_test\n",
    "                \n",
    "            else:\n",
    "                results[ds,seed,:] = float('nan')\n",
    "                \n",
    "            inference_time = 0\n",
    "                \n",
    "            for x,y in test_loader:\n",
    "                X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "                start_time = time.time()\n",
    "                model(X_test[:1, :, :])\n",
    "                end_time = time.time()\n",
    "                inference_time = end_time - start_time\n",
    "                break\n",
    "            results[ds, seed, 2] = inference_time\n",
    "                \n",
    "            temp_result = [datainfo['dataname'], seed, results[ds, seed, 0].item(), results[ds, seed, 1].item(), results[ds, seed, 2].item()]\n",
    "            all_results.append(temp_result)\n",
    "\n",
    "    columns = ['dataset', 'seed', 'acc_valid', 'acc_test', 'average_time']\n",
    "    all_results.sort(key=lambda x: x[0])            \n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    # Save the DataFrame to an Excel file\n",
    "    if not os.path.exists(f\"./evaluation/\"):\n",
    "        os.makedirs(f\"./evaluation/\")\n",
    "    excel_filename = f\"./evaluation/var{int(var*100)}_evaluation_results_analysis.xlsx\"\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "    print(f\"Results have been saved to {excel_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
